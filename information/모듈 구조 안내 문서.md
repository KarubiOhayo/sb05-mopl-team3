
---

# 모노레포 멀티모듈 구조 & 모듈 역할 안내 (Mopl)

## 0. 한 줄 요약

* **api**: REST API + DB의 주된 쓰기/읽기 주체
* **socket**: WebSocket/SSE 기반 실시간(시청 세션/DM 실시간 수신)
* **worker**: Kafka 이벤트 처리 + 비동기 후처리(집계 갱신/알림 생성 등)
* **batch**: 정기 작업(정리/재집계/인덱싱 등)
* **core**: 안전하게 공유 가능한 “계약”(ErrorCode, 이벤트 DTO 등)
* **infrastructure(선택)**: Redis/Kafka/DB 연결 및 공통 설정 코드(서버를 띄우는 게 아님)
* **gateway**: Nginx reverse proxy (외부 진입점)
* **monitoring**: Prometheus/Grafana 설정 및 운영 스택

---

## 1. 모듈 구성

### 1.1 배포(컨테이너) 대상 모듈

* `gateway` (Nginx)
* `api` (Spring Boot)
* `socket` (Spring Boot)
* `worker` (Spring Boot)
* `batch` (Spring Boot, 스케줄/배치 잡)

### 1.2 라이브러리/지원 모듈 (컨테이너로 따로 배포하지 않음)

* `core`
* `infrastructure` (선택)
* `monitoring` (도구 설정/실행용: prom/grafana)

---

## 2. 의존성(Dependency) 규칙

### 2.1 권장 의존 방향

* `core` ← (api, socket, worker, batch, infrastructure)
* `infrastructure` ← (api, socket, worker, batch)
* **애플리케이션 모듈끼리 직접 의존 금지**

  * 예: `api`가 `worker` 코드를 import ❌
  * 예: `socket`이 `api` 내부 서비스를 import ❌

### 2.2 모듈 간 통신 원칙

* 기본: **Kafka 이벤트(비동기)**
* 실시간 상태 공유/세션: **Redis**
* REST 호출: 필요할 때만 최소화(단방향 권장)

---

## 3. DB 스키마 기준 “데이터 소유권” (테이블 → 담당 모듈)

schema.sql에 정의된 주요 테이블(14개):

* users, contents, tags, content_tags
* playlists, playlist_contents, playlist_subscriptions
* reviews, follows
* conversations, conversation_participants, direct_messages
* notifications
* watching_sessions

### 3.1 기본 원칙

* **DB는 api/worker/batch가 주로 만진다.**
* socket은 실시간 통신이 주 역할이라 DB에 직접 쓰기는 “선택”이지만,

  * 요구사항상 **DM은 실시간(WebSocket)로 주고받고**, 저장/조회/읽음 처리는 REST API도 존재하므로
    **저장은 api 또는 worker가 담당**하는 쪽이 운영/정합성에 유리함.

### 3.2 추천 매핑(현실 버전)

* `api`가 **정합성의 단일 진실(source of truth)** 역할

  * users/contents/playlists/reviews/follows/notifications/conversations/direct_messages 기본 CRUD
* `worker`는 **집계/비동기 후처리**

  * contents의 평균 평점/리뷰 수 같은 집계, 알림 생성, (선택) 검색 인덱싱 이벤트 처리
* `batch`는 **정리/재집계/주기 처리**

  * 오래된 데이터 정리, 재계산, 인덱싱 리빌드 등
* `socket`은 **DB 직접 접근을 최대한 줄이고**, 실시간 전달/세션 관리 중심

  * 시청 세션 정보는 WebSocket으로 주고받는 요구사항이 있으니 socket이 주도

---

## 4. 모듈별 역할 상세

## 4.1 `core` 모듈 (공통 계약)

### 목적

모듈 간 “공유해도 안전한” 최소 계약을 한 곳에서 관리

### 포함(OK)

* `ErrorCode` (공통 에러 enum)
* `ErrorResponse` / 공통 에러 포맷
* Kafka Event DTO (예: ReviewCreatedEvent, WatchingSessionEvent, NotificationEvent 등)
* 토픽명/Redis key prefix 같은 공통 상수

### 포함(금지)

* 도메인별 Request/Response DTO
* 비즈니스 로직(Service)
* JPA Entity/Repository

> core는 **비대해지면 독**이야. “계약만” 넣는다고 생각해.

---

## 4.2 `infrastructure` 모듈 (선택/권장, 코드 레벨 인프라)

### 목적

Redis/Kafka/DB 같은 인프라를 **각 앱이 동일한 방식으로 사용**하도록 연결/설정/도구 제공

### 포함(OK)

* Kafka Producer/Consumer 공통 설정(직렬화 규칙 포함)
* RedisTemplate/Cache/PubSub 공통 설정
* 공통 Properties 바인딩, 공통 유틸(키 생성기, 락 등)

### 포함(금지)

* Redis/Kafka “서버를 띄우는” 코드/compose/IaC
  (그건 인프라 구축 영역)

> 즉, infrastructure 모듈이 있다고 해서 “인프라 서버가 같이 배포된다”가 아니고,
> **앱 컨테이너 안에 라이브러리처럼 포함**되는 거야.

---

## 4.3 `api` 모듈 (REST API)

api-docs.json 기준으로 주요 엔드포인트:

* `/api/auth/*` (sign-in, refresh, sign-out, reset-password)
* `/api/users`, `/api/users/{userId}` + role/password/locked 등 관리성 API
* `/api/contents`, `/api/contents/{contentId}`
* `/api/reviews`, `/api/reviews/{reviewId}`
* `/api/playlists` + 구독/콘텐츠 추가/삭제
* `/api/follows`
* `/api/conversations` + DM 조회/읽음 처리
* `/api/notifications`
* `/api/*/watching-sessions` (콘텐츠별, 사용자별 조회)

### 책임

* HTTP 요청 처리, 입력 검증, 트랜잭션, DB CRUD
* 인증/인가 (WebSocket 인증 토큰 발급/검증의 기준도 api가 가짐)
* Redis 사용

  * refresh token 저장소(요구사항)
  * 캐시(요구사항)
* Kafka 이벤트 발행

  * “비동기 후처리”가 필요한 시점에 이벤트 발행(집계/알림/인덱싱 등)

### 비책임(여기 넣지 말자)

* Kafka 소비(Listener) 로직 → worker
* 주기적 잡 실행 → batch
* 실시간 전송/브로드캐스트 → socket

---

## 4.4 `socket` 모듈 (WebSocket / SSE 실시간)

요구사항 기준:

* 시청 세션 정보는 WebSocket으로 주고받음
* DM(쪽지)은 “활성 대화”는 WebSocket, “다른 대화”는 SSE로 수신

### 책임

* WebSocket 연결 수립/인증(WebSocket Security)
* 시청 세션 실시간 처리

  * 접속/퇴장/시청 상태 업데이트
  * Redis에 세션/룸 상태 저장(다중 인스턴스 대응)
* DM 실시간 수신(WS) + 백그라운드 수신(SSE)

  * “전송”은 socket이 담당하되,
  * “영속 저장/읽음 처리”는 api(또는 worker) 쪽이 책임지는 걸 권장

### 비책임

* DB 정합성/트랜잭션 중심 로직은 api로 몰기(초기엔 특히)
* 비동기 집계/알림 생성은 worker로 위임

---

## 4.5 `worker` 모듈 (Kafka Consumer + 비동기 후처리)

### 책임

* Kafka 이벤트 소비(@KafkaListener)
* 집계/후처리

  * 예: 리뷰 이벤트 → contents 평균 평점/리뷰 수 갱신
  * 예: DM 수신 → 알림 생성(요구사항에 “DM 받으면 알림”)
  * 예: 팔로우/플레이리스트 구독 등 → 알림 생성
* 안정성 책임

  * 재시도/실패 처리(최소한 DLQ 또는 실패 로그 전략)
  * 멱등성(eventId 기반 중복 처리 방어) 권장

### 비책임

* 외부 REST 엔드포인트 제공(Controller) → api

---

## 4.6 `batch` 모듈 (정기 작업)

요구사항에 배치 관련 요구가 있고, 검색(Elasticsearch/OpenSearch)도 언급됨.

### 책임

* 정기 실행 작업

  * 데이터 정리(만료/불필요 레코드 cleanup)
  * 재집계(필요 시 contents 평점 등 재계산)
  * 검색 인덱싱 리빌드(선택)
* 실행 방식

  * 로컬: 스케줄러/수동 실행
  * ECS: Scheduled Task 권장

---

## 4.7 `gateway` 모듈 (Nginx reverse proxy)

### 책임

* 외부 트래픽 진입점
* 라우팅:

  * `/api/*` → api
  * `/ws/*` → socket (WebSocket upgrade 설정 포함)
* 공통 헤더, 타임아웃, CORS(필요 시)

---

## 4.8 `monitoring` 모듈 (Prometheus/Grafana)

### 책임

* Prometheus scrape 설정(각 앱의 `/actuator/prometheus`)
* Grafana datasource/dashboards
* 로컬/개발 환경에서 “다 같이 띄워서” 관측 가능하게 구성

### 앱 모듈이 해야 할 것(공통)

* actuator 활성화
* prometheus endpoint 노출
* 핵심 메트릭(예: websocket 연결 수, 이벤트 처리량) 커스텀 계측(시간 되면)

---

## 5. 데이터 흐름(대표 시나리오)

### 5.1 리뷰 생성 → 컨텐츠 집계 갱신

1. api: 리뷰 생성(REST) + DB 저장
2. api: `ReviewCreatedEvent` Kafka 발행
3. worker: 이벤트 소비 → contents 집계(average_rating/review_count) 갱신

### 5.2 DM 수신 → 실시간 전달 + 알림

1. socket: WS로 DM 수신/전달
2. (권장) api 또는 worker가 DB 저장(직접 호출 또는 이벤트)
3. worker: `DMReceivedEvent` 기반으로 notifications 생성
4. socket/SSE: 알림/DM 수신 실시간 전달

### 5.3 시청 세션

1. socket: WebSocket으로 시청 세션 이벤트 수신
2. Redis: 현재 시청 상태/세션을 저장(다중 인스턴스 공유)
3. (선택) worker: 집계 필요하면 watcher_count 갱신 이벤트 처리

---

## 6. 개발 규칙(팀 합의로 박아두면 좋은 것)

### 6.1 공통 설정/프로필

* local/docker/dev/prod 프로필 분리
* Kafka bootstrap:

  * 호스트 실행: `localhost:9092`
  * 컨테이너 내부: `kafka:29092` 같은 내부 리스너
* Redis host:

  * 호스트 실행: `localhost`
  * 컨테이너 내부: `redis`

### 6.2 이벤트/Redis 키 규칙(최소 강제)

* Kafka Event는 core에 DTO로 정의하고 버전/시간/eventId 필드를 포함 권장
* Redis key prefix 통일

  * 예: `rt:{userId}:{deviceId}` (refresh token)
  * 예: `ws:session:{userId}` (웹소켓 세션)
* TTL 정책: 캐시/토큰/세션 별로 구분

---

## 7. “어디까지 분리하고 어디서 멈출지” 가이드

* 너희는 도메인 모듈 분리를 안 하기로 했으니까,

  * **공통 공유는 core(계약) + infrastructure(인프라 설정)까지만**
  * 비즈니스 로직/DTO/Entity는 각 앱에 남기기
* 중복이 생겨도 괜찮은 영역:

  * API 응답 DTO, 서비스 로직, 일부 유효성 검사
* 중복이 생기면 위험한 영역(공통화 권장):

  * Kafka 직렬화 규칙/이벤트 DTO
  * Redis 연결/템플릿 설정
  * 공통 에러 포맷

---

